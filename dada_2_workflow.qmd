---
title: "Untitled"
format: html
---

```{r}
library(dada2)
library(dplyr)
library(plyr)
library(ggplot2)
library(stringr)
library(tidyverse)
library(microbiomeMarker)
library(LinDA)
library(Maaslin2)
library(phyloseq)
library(LinDA)
library(vegan)
library(ggpubr)
library(ggtext)
library(ConQuR)
library(doParallel) 
```


## Initial instructions: ##
1. Retreive the directory path of the file containing the FASTQ files
2. create a subdirectory in that directory called "filtered"
3. create another subdirectory somewhere else where you want to run all of your analysis from, set this as the working directory for R
    this r markdown file should be in that directory
4. In the working directory make sure there is the silva_nr99_v138.1_train_set file and the silva_species_assignments file

## Set up inital things ##
```{r}
# Set this as the path of where your FASTQ files are 
path<-paste0(getwd(),"/fastqs")

# Set this to the group name of who the files belong to, and if you want you can throw a date in there
group_name <- "Sanford_Aug_2023"

# Seed for reproducibility
set.seed(2023)


```


## Run dada2 ##

# Run this chunk to prepare files
```{r}
list.files(path)

#Here make sure the FASTQs follow the typical naming convention of SampleID_randomstuff_R1_001.fastq
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

# Check out quality plots by changing the number, pick a good cut off to trim the end of the reads, the reverse read will probably need to be trimmed more
```{r}
plotQualityProfile(fnFs[10:12])
plotQualityProfile(fnRs[10:12])

```


# Change the trunc length and run this chunk, look at the output, some files will have so few reads that they may need to be removed 
```{r}

# Remove primers 
#forw <- ""
#rev <-

# Filtering files and placing in the directory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names


?filterAndTrim

# Here you set the trim at the truncLen parameter
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,200),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE, trimLeft = 30)

# Learning the error rate for DADA2 algorithm
errF <- learnErrors(filtFs, multithread=TRUE)
errR <- learnErrors(filtRs, multithread=TRUE)

print(out)
plotErrors(errF, nominalQ=TRUE)
```


# Run core program, this chunk takes the longest
```{r}
# Running the core algo
set.seed(2023)
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
set.seed(2023)
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)

# Merging fwd and rev reads
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)

# Making table of reads and removing chimeras
seqtab <- makeSequenceTable(mergers)
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)

# Assigning taxa with a pretrained classifier, up to genus level
taxa <- assignTaxonomy(seqtab.nochim, "silva_nr99_v138.1_train_set.fa.gz", multithread=TRUE)
# Adds species only with an exact match to the ASV 
taxa <- addSpecies(taxa, "silva_species_assignment_v138.1.fa.gz")


```



## Making the files for analysis ##
# This is just a bunch of data wrangling to make nice tables containing the results, running this chunk will write 5 files, the group name gets added to the front so you will know who it came from 
1. A file showing counts and taxonomy for all ASVs, it includes the DNA sequence of the ASV
2. Raw counts for species level
3. Raw counts for family level
4. Proportion abundance species level
5. Proportion abundance family level
```{r}
# transpose and set as df with the dna sequences as a variable
seqtab_nochim_t<- t(seqtab.nochim)
seqtab_nochim_t_df <- data.frame(seqtab_nochim_t)

# set as df with dna sequence variable
taxa_df<- data.frame(taxa)

# Write a file that contains the counts, the DNA ASV, and both kinds of taxonomic classifications
df_final <- cbind(taxa_df,seqtab_nochim_t_df)
write.csv(df_final,file = paste0(group_name,"level_7_ASVs.csv"),row.names = FALSE,quote=FALSE)
write.csv(df_final,file = paste0(group_name,"level_7_ASVs_with_seqs.csv"),row.names = TRUE,quote=FALSE)

```

